{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b748641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import SpeechT5ForSpeechToText, SpeechT5Model, SpeechT5Config, SpeechT5PreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ab41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "st5_asr = SpeechT5ForSpeechToText.from_pretrained(\"microsoft/speecht5_asr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8803aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load(\"../checkpoints/speecht5_base.pt\", map_location=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c9a3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ckpt['model'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a310854",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 speecht5.encoder.wrapped_encoder.layers.3.attention.k_proj.weight torch.Size([768, 768])\n",
      "2 speecht5.encoder.wrapped_encoder.layers.3.attention.k_proj.bias torch.Size([768])\n",
      "3 speecht5.encoder.wrapped_encoder.layers.3.attention.v_proj.weight torch.Size([768, 768])\n",
      "4 speecht5.encoder.wrapped_encoder.layers.3.attention.v_proj.bias torch.Size([768])\n",
      "5 speecht5.encoder.wrapped_encoder.layers.3.attention.q_proj.weight torch.Size([768, 768])\n",
      "6 speecht5.encoder.wrapped_encoder.layers.3.attention.q_proj.bias torch.Size([768])\n",
      "7 speecht5.encoder.wrapped_encoder.layers.3.attention.out_proj.weight torch.Size([768, 768])\n",
      "8 speecht5.encoder.wrapped_encoder.layers.3.attention.out_proj.bias torch.Size([768])\n",
      "9 speecht5.encoder.wrapped_encoder.layers.3.layer_norm.weight torch.Size([768])\n",
      "10 speecht5.encoder.wrapped_encoder.layers.3.layer_norm.bias torch.Size([768])\n",
      "11 speecht5.encoder.wrapped_encoder.layers.3.feed_forward.intermediate_dense.weight torch.Size([3072, 768])\n",
      "12 speecht5.encoder.wrapped_encoder.layers.3.feed_forward.intermediate_dense.bias torch.Size([3072])\n",
      "13 speecht5.encoder.wrapped_encoder.layers.3.feed_forward.output_dense.weight torch.Size([768, 3072])\n",
      "14 speecht5.encoder.wrapped_encoder.layers.3.feed_forward.output_dense.bias torch.Size([768])\n",
      "15 speecht5.encoder.wrapped_encoder.layers.3.final_layer_norm.weight torch.Size([768])\n",
      "16 speecht5.encoder.wrapped_encoder.layers.3.final_layer_norm.bias torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "ctr1 = 1\n",
    "for name, p in st5_asr.named_parameters():\n",
    "    if name.startswith(\"speecht5.encoder.wrapped_encoder.layers.3\"): #encoder.wrapped_encoder.layers.0\n",
    "        print(ctr1, name, p.size())\n",
    "        ctr1 += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9bb7d493",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 encoder.layers.0.self_attn.k_proj.weight torch.Size([768, 768])\n",
      "2 encoder.layers.0.self_attn.k_proj.bias torch.Size([768])\n",
      "3 encoder.layers.0.self_attn.v_proj.weight torch.Size([768, 768])\n",
      "4 encoder.layers.0.self_attn.v_proj.bias torch.Size([768])\n",
      "5 encoder.layers.0.self_attn.q_proj.weight torch.Size([768, 768])\n",
      "6 encoder.layers.0.self_attn.q_proj.bias torch.Size([768])\n",
      "7 encoder.layers.0.self_attn.out_proj.weight torch.Size([768, 768])\n",
      "8 encoder.layers.0.self_attn.out_proj.bias torch.Size([768])\n",
      "9 encoder.layers.0.self_attn_layer_norm.weight torch.Size([768])\n",
      "10 encoder.layers.0.self_attn_layer_norm.bias torch.Size([768])\n",
      "11 encoder.layers.0.fc1.weight torch.Size([3072, 768])\n",
      "12 encoder.layers.0.fc1.bias torch.Size([3072])\n",
      "13 encoder.layers.0.fc2.weight torch.Size([768, 3072])\n",
      "14 encoder.layers.0.fc2.bias torch.Size([768])\n",
      "15 encoder.layers.0.final_layer_norm.weight torch.Size([768])\n",
      "16 encoder.layers.0.final_layer_norm.bias torch.Size([768])\n",
      "17 encoder.layers.0.norm_k.weight torch.Size([64])\n",
      "18 encoder.layers.0.norm_k.bias torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "compat = {}\n",
    "ctr2 = 1\n",
    "for name, p in ckpt['model'].items():\n",
    "#     if name.startswith(\"speech_encoder_prenet\"):\n",
    "#         print(ctr2, name, end=\" -> \")\n",
    "#         parts = name.split(\".\")\n",
    "#         tmp = name.replace(\"speech\", \"speecht5\")\n",
    "#         tmp = tmp.replace(\"_\", \".\", 2)\n",
    "#         tmp = tmp.replace(\"feature_extractor\", \"feature_encoder\")\n",
    "#         tmp = tmp.replace(\".0.weight\", \".conv.weight\")\n",
    "        \n",
    "#         if tmp.endswith(\"mask_emb\"):\n",
    "#             tmp = tmp.replace(\"mask_emb\", \"masked_spec_emb\")\n",
    "        \n",
    "#         print(tmp)\n",
    "#         ctr2 += 1\n",
    "    if name.startswith(\"encoder.layers.0\"):\n",
    "        print(ctr2, name, p.size())\n",
    "        ctr2 += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8529ea9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = ((2359296 * 2) + (3072 * 2) + (768 * 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "46f3cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = ((1179648 + 589824 + 589824) + (768 * 4) + 1536) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "307a011a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.726272, 2.363904, 7.090176])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray([lstm, ca, (lstm+ca)]) / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bc7b157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7090176"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " 7077888 + 12288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "851364ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6665944540727903"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm/(lstm+ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83d33905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3334055459272097"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca/(lstm+ca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bdbff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "st5_cfg = SpeechT5Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06fa14c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "st5_model = SpeechT5PreTrainedModel(st5_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e23256f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechT5PreTrainedModel()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st5_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9eefcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce1552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57dc14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "st5_cfg = SpeechT5Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f35650ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "st5_cfg.feat_extract_norm = \"layer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df059027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechT5Config {\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"apply_spec_augment\": true,\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"conv_bias\": false,\n",
       "  \"conv_dim\": [\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512,\n",
       "    512\n",
       "  ],\n",
       "  \"conv_kernel\": [\n",
       "    10,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    3,\n",
       "    2,\n",
       "    2\n",
       "  ],\n",
       "  \"conv_stride\": [\n",
       "    5,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2,\n",
       "    2\n",
       "  ],\n",
       "  \"decoder_attention_heads\": 12,\n",
       "  \"decoder_ffn_dim\": 3072,\n",
       "  \"decoder_layerdrop\": 0.1,\n",
       "  \"decoder_layers\": 6,\n",
       "  \"decoder_start_token_id\": 2,\n",
       "  \"encoder_attention_heads\": 12,\n",
       "  \"encoder_ffn_dim\": 3072,\n",
       "  \"encoder_layerdrop\": 0.1,\n",
       "  \"encoder_layers\": 12,\n",
       "  \"encoder_max_relative_position\": 160,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"feat_extract_activation\": \"gelu\",\n",
       "  \"feat_extract_norm\": \"layer\",\n",
       "  \"feat_proj_dropout\": 0.0,\n",
       "  \"guided_attention_loss_num_heads\": 2,\n",
       "  \"guided_attention_loss_scale\": 10.0,\n",
       "  \"guided_attention_loss_sigma\": 0.4,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"mask_feature_length\": 10,\n",
       "  \"mask_feature_min_masks\": 0,\n",
       "  \"mask_feature_prob\": 0.0,\n",
       "  \"mask_time_length\": 10,\n",
       "  \"mask_time_min_masks\": 2,\n",
       "  \"mask_time_prob\": 0.05,\n",
       "  \"max_speech_positions\": 4000,\n",
       "  \"max_text_positions\": 450,\n",
       "  \"model_type\": \"speecht5\",\n",
       "  \"num_conv_pos_embedding_groups\": 16,\n",
       "  \"num_conv_pos_embeddings\": 128,\n",
       "  \"num_feat_extract_layers\": 7,\n",
       "  \"num_mel_bins\": 80,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"positional_dropout\": 0.1,\n",
       "  \"reduction_factor\": 2,\n",
       "  \"scale_embedding\": false,\n",
       "  \"speaker_embedding_dim\": 512,\n",
       "  \"speech_decoder_postnet_dropout\": 0.5,\n",
       "  \"speech_decoder_postnet_kernel\": 5,\n",
       "  \"speech_decoder_postnet_layers\": 5,\n",
       "  \"speech_decoder_postnet_units\": 256,\n",
       "  \"speech_decoder_prenet_dropout\": 0.5,\n",
       "  \"speech_decoder_prenet_layers\": 2,\n",
       "  \"speech_decoder_prenet_units\": 256,\n",
       "  \"transformers_version\": \"4.30.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"use_guided_attention_loss\": true,\n",
       "  \"vocab_size\": 81\n",
       "}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st5_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "694f1091",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpeechT5Model(config=st5_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39923654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechT5Model(\n",
       "  (encoder): SpeechT5EncoderWithoutPrenet(\n",
       "    (wrapped_encoder): SpeechT5Encoder(\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x SpeechT5EncoderLayer(\n",
       "          (attention): SpeechT5Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): SpeechT5FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (embed_positions): SpeechT5RelativePositionalEncoding(\n",
       "        (pe_k): Embedding(320, 64)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): SpeechT5DecoderWithoutPrenet(\n",
       "    (wrapped_decoder): SpeechT5Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x SpeechT5DecoderLayer(\n",
       "          (self_attn): SpeechT5Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): SpeechT5Attention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): SpeechT5FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "774e8d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechT5Encoder(\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x SpeechT5EncoderLayer(\n",
       "      (attention): SpeechT5Attention(\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): SpeechT5FeedForward(\n",
       "        (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (intermediate_act_fn): GELUActivation()\n",
       "        (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (embed_positions): SpeechT5RelativePositionalEncoding(\n",
       "    (pe_k): Embedding(320, 64)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.wrapped_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a411ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "st5_cfg_2 = SpeechT5Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddd71505",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = SpeechT5Model(config=st5_cfg_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb90a2c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpeechT5Encoder(\n",
       "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0-11): 12 x SpeechT5EncoderLayer(\n",
       "      (attention): SpeechT5Attention(\n",
       "        (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (feed_forward): SpeechT5FeedForward(\n",
       "        (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "        (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (intermediate_act_fn): GELUActivation()\n",
       "        (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (embed_positions): SpeechT5RelativePositionalEncoding(\n",
       "    (pe_k): Embedding(320, 64)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.encoder.wrapped_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ec6a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
